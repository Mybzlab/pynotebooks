{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905936cd",
   "metadata": {},
   "source": [
    "# Pipeline for Tracking Many Files\n",
    "\n",
    "\n",
    "##### Luco Buise\n",
    "##### MSc Thesis: Radboud University\n",
    "\n",
    "22-05-2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c6f17",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "\n",
    "import cv2\n",
    "import trackpy as tp\n",
    "import ipywidgets as widgets\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from ipywidgets import HBox, Textarea, interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc06ae3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e476f6-b935-4a1f-8445-a00f04e3c38a",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743bb6d-6b06-46fd-a965-43864789032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_circles(image, min_radius, max_radius, param1, param2, dp=1.2):\n",
    "    min_dist = int(0.9 * max_radius)\n",
    "\n",
    "    # apply Hough transform\n",
    "    circles = cv2.HoughCircles(image, cv2.HOUGH_GRADIENT, dp, min_dist,\n",
    "                               param1=param1, param2=param2,\n",
    "                               minRadius=min_radius, maxRadius=max_radius)\n",
    "    return circles\n",
    "    \n",
    "def capture_frame(video_obj, frame_num):\n",
    "    video_obj.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = video_obj.read()\n",
    "    if not ret:\n",
    "        return None # if reached ending, stop\n",
    "    return frame\n",
    "\n",
    "def draw_circles(ax, circles):\n",
    "    if circles is not None:\n",
    "        for pt in circles[0]:\n",
    "            x, y, r = pt\n",
    "            circle = plt.Circle((x, y), r, color='r', fill=False)\n",
    "            ax.add_patch(circle)\n",
    "\n",
    "def crop_image(img,x0,y0,x1,y1):\n",
    "    return img[y0:y1,x0:x1,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c31536-a0d7-45d5-b473-d772eb077a99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134883e-3a66-47f5-b0ae-9ddfa5ba04a3",
   "metadata": {},
   "source": [
    "Fill in the parameters found using the $\\textbf{tracking\\_pipeline\\_v2.ipynb}$ notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af707a1-9248-4723-9891-2fab15988da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters used for all videos (mostly global params)\n",
    "\n",
    "# ratio between cm and pixels\n",
    "px_cm_ratio = 0.1905933580903535\n",
    "\n",
    "# cropping of the video\n",
    "crop_x = (581, 1378) \n",
    "crop_y = (87, 862)\n",
    "\n",
    "# parameters for bot detection\n",
    "canny_edge_thresh = 47 # how sharp are the edges considered\n",
    "circle_detection_thresh = 15 # lower = more sensitive, but can detect false positives.\n",
    "radiusMin = 10\n",
    "radiusMax = 19\n",
    "\n",
    "# what part of the video do you want to track\n",
    "start_frame = 0\n",
    "end_frame = 0 # use 0 if end, otherwise use negative number\n",
    "\n",
    "# parameters for trajectory creation\n",
    "max_dist = 10 # maximum distance particle can move between frames\n",
    "memory = 10 # maximum number of frames during which a feature can vanish, and be considered the same particle\n",
    "min_length = 100 # minimum length for a trajectory\n",
    "\n",
    "# do you want to smoothen the trajectories\n",
    "smoothen = True\n",
    "\n",
    "# do you want to see the plots of the trajectories (as a sanity check)\n",
    "show_plot = True\n",
    "\n",
    "# which dir to save all the files\n",
    "save_dir = \"cluster_trajs\"\n",
    "\n",
    "# if dir does not exist, create it\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071453cd",
   "metadata": {},
   "source": [
    "## Import videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c0c0bc-270d-4bca-8336-3dce381853d8",
   "metadata": {},
   "source": [
    "Define the folder in which all the files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d2faa-0526-4ff0-aac6-4818ae6fd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder in which the video folders are located\n",
    "og_folder = \"lab_recordings\"\n",
    "\n",
    "# folder in which all mp4s are located\n",
    "dir_name = \"cluster_dispersion_v3\"\n",
    "full_dir = os.path.join(og_folder, dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2025c5e-b65e-46eb-be95-3873394127c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "\n",
    "# loop over files in dir\n",
    "for f in os.listdir(full_dir):\n",
    "    # only get mp4s\n",
    "    if f.lower().endswith('.mp4'):\n",
    "        all_files.append(f)\n",
    "\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9857e09-ffff-4c93-b423-da704751de86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03ac5c-680b-44f7-be66-5aa3a9855d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe filled with all annotated frames\n",
    "def get_frame_df(video_path, start_frame, end_frame):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frames = np.array(range(start_frame, frame_count + end_frame, 1)) # assumes end_frame is negative\n",
    "    \n",
    "    circle_detections = []\n",
    "    \n",
    "    for i, frame_num  in enumerate(frames):\n",
    "        img = capture_frame(video, frame_num )\n",
    "        if img is not None:\n",
    "            img = crop_image(img, crop_x[0], crop_y[0], crop_x[1], crop_y[1])\n",
    "            grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            circles = detect_circles(grayImage, radiusMin, radiusMax, canny_edge_thresh, circle_detection_thresh)\n",
    "        \n",
    "            if circles is not None:\n",
    "                for circle in circles[0]:  # circles[0] is the list of detections\n",
    "                    x, y, r = circle\n",
    "                    circle_detections.append([x, y, r, frame_num])\n",
    "        \n",
    "            if frame_num  % 500 == 0:\n",
    "                print(\"Done with frame\", frame_num , \"/\", frame_count)\n",
    "\n",
    "    return pd.DataFrame(circle_detections, columns=[\"x\", \"y\", \"size\", \"frame\"])\n",
    "\n",
    "# try to link all trajectories using the annotated frames\n",
    "def get_trajs(frame_df):\n",
    "    # get trajectories from the locations\n",
    "    t = tp.link(frame_df, max_dist, memory=memory)\n",
    "    \n",
    "    # remove short trajectories\n",
    "    t1 = tp.filter_stubs(t, min_length)\n",
    "    \n",
    "    # compare the number of particles in the unfiltered and filtered data.\n",
    "    print('Before stub filtering:', t['particle'].nunique())\n",
    "    print('After stub filtering:', t1['particle'].nunique())\n",
    "\n",
    "    return t1\n",
    "\n",
    "# smoothen the trajectories\n",
    "def smooth_trajectories(df, window_length=10, polyorder=2):   \n",
    "    # make sure 'frame' is only a column, not an index level\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Make sure data is sorted by particle and frame\n",
    "    df = df.sort_values(['particle', 'frame']).reset_index(drop=True)\n",
    "    \n",
    "    # group by particle and smooth each trajectory\n",
    "    for pid, group in df.groupby('particle'):\n",
    "        n = len(group)\n",
    "        \n",
    "        # adjust window_length if too short\n",
    "        wl = min(window_length, n if n % 2 == 1 else n - 1)\n",
    "        if wl < polyorder + 2:\n",
    "            # If trajectory too short for savgol, just copy raw data\n",
    "            df.loc[group.index, 'x'] = group['x']\n",
    "            df.loc[group.index, 'y'] = group['y']\n",
    "            continue\n",
    "        \n",
    "        # smooth x and y separately\n",
    "        df.loc[group.index, 'x'] = savgol_filter(group['x'], wl, polyorder)\n",
    "        df.loc[group.index, 'y'] = savgol_filter(group['y'], wl, polyorder)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# plot the trajectories for sanity check\n",
    "def plot_trajectories(trajs):\n",
    "    plt.figure()\n",
    "\n",
    "    # frame size\n",
    "    cropped_x_res = crop_x[1] - crop_x[0]\n",
    "    cropped_y_res = crop_y[1] - crop_y[0]\n",
    "    \n",
    "    # make plot same shape&size as the frames\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([0, cropped_x_res])\n",
    "    ax.set_ylim([0, cropped_y_res])\n",
    "    \n",
    "    # add scale bar\n",
    "    scale_bar_length_cm = 30\n",
    "    \n",
    "    # convert scale bar length from cm to pixels (using ratio calculated in beginning)\n",
    "    scale_bar_length_pxs = scale_bar_length_cm / px_cm_ratio\n",
    "    \n",
    "    # location of the scale bar\n",
    "    x_scale_start = 50\n",
    "    y_scale_start = cropped_y_res - 50\n",
    "    scale_bar_end = x_scale_start + scale_bar_length_pxs\n",
    "    \n",
    "    # draw a horizontal line for the scale bar\n",
    "    plt.plot([x_scale_start, scale_bar_end], [y_scale_start, y_scale_start], color='black', lw=2)\n",
    "    \n",
    "    # add label for the scale bar\n",
    "    plt.text(x_scale_start + scale_bar_length_pxs / 2, y_scale_start - 5, f'{scale_bar_length_cm} cm', \n",
    "             color='black', ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # plot traj\n",
    "    tp.plot_traj(trajs, label=True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# save trajectory dataframe and parameters as pickle using dict\n",
    "def save_as_pickle(df, video_name):\n",
    "    cropped_x_res = crop_x[1] - crop_x[0]\n",
    "    cropped_y_res = crop_y[1] - crop_y[0]\n",
    "\n",
    "    file_name = video_name + \".pkl\"\n",
    "\n",
    "    save_file_path = os.path.join(save_dir, file_name)\n",
    "    \n",
    "    # create dict\n",
    "    traj_dict = {\"traj_df\":df, \"px_cm_ratio\":px_cm_ratio, \"x_res_px\":cropped_x_res, \"y_res_px\":cropped_y_res}\n",
    "    \n",
    "    # save dict as pickle\n",
    "    try:\n",
    "        with open(save_file_path, 'wb') as file:\n",
    "            pickle.dump(traj_dict, file)\n",
    "            print(\"Pickled data:\", save_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error pickling dictionary: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2e303-3387-47b2-807b-eecc9805b2b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run the full pipeline over all files in the dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfaace8-20c0-4a06-9e80-8282ac5d2621",
   "metadata": {},
   "source": [
    "Once all paramaters are set and you ran the cells above, run this cell and everything will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc1bd2-831f-444b-ac50-c1d6b06452d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_processed = 0\n",
    "\n",
    "# loop over all files\n",
    "for video_name in all_files:\n",
    "    print(\"Start processing\", video_name)\n",
    "\n",
    "    # create path as string\n",
    "    video_path = os.path.join(full_dir, video_name)\n",
    "    \n",
    "    # annotate all the frames\n",
    "    frame_df = get_frame_df(video_path, start_frame, end_frame)\n",
    "\n",
    "    # get the trajectories\n",
    "    trajs = get_trajs(frame_df)\n",
    "\n",
    "    # smooth the trajs if wanted\n",
    "    if smoothen:\n",
    "        trajs = smooth_trajectories(trajs)\n",
    "\n",
    "    # plot if wanted\n",
    "    if show_plot:\n",
    "        plot_trajectories(trajs)\n",
    "\n",
    "    # save everything to a pickle\n",
    "    save_as_pickle(trajs, video_name.strip(\".mp4\"))\n",
    "\n",
    "    files_processed += 1\n",
    "\n",
    "    # progress update\n",
    "    print(\"Done with\", video_name, \",\", files_processed, \"/\", len(all_files), \"completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
